{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "UosZYzDofchv"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from pm_utils import get_data\n",
    "from pm_utils import create_sliding_windows_with_labels\n",
    "from pm_utils import NDStandardScaler\n",
    "from keras.src.callbacks import EarlyStopping\n",
    "import keras\n",
    "from keras import Input, Model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.layers import LSTM, Dense, Dropout, SimpleRNN, GRU, Conv1D, GlobalMaxPool1D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "random_seed = 812\n",
    "keras.utils.set_random_seed(random_seed)\n",
    "np.random.seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r8pM4fQffchy"
   },
   "outputs": [],
   "source": [
    "train_percent = 0.9\n",
    "validation_percent = 0.1\n",
    "\n",
    "T = 6\n",
    "T_shift = 4\n",
    "path = 'C:/Users/mkedzia/Desktop/praca-magisterska/binance-data/aaa/data/BNB/BNB-merged-data.csv'\n",
    "\n",
    "columns, input_data, targets = get_data(path=path, base_m=True, trade_metrics=True, trade_metrics_m=False,\n",
    "                                        google=True, t=T, t_shift=T_shift)\n",
    "targets = (targets >= 0.0)\n",
    "\n",
    "k_features = 18\n",
    "\n",
    "mi = mutual_info_classif(input_data, targets, random_state=0)\n",
    "\n",
    "sorted_indices = np.argsort(mi)[::-1]\n",
    "sorted_features = np.array(columns)[sorted_indices]\n",
    "sorted_mi = mi[sorted_indices]\n",
    "\n",
    "selector = SelectKBest(mutual_info_classif, k=k_features)\n",
    "selected_features = selector.fit_transform(input_data, targets)\n",
    "selected_mask = selector.get_support()\n",
    "# input_data = selected_features\n",
    "\n",
    "selected_features_labels = [col for col, is_selected in zip(columns, selected_mask) if is_selected]\n",
    "rejected_features_labels = [col for col, is_selected in zip(columns, selected_mask) if not is_selected]\n",
    "\n",
    "print(\"Wybrane cechy:\", selected_features_labels)\n",
    "print(\"Odrzucone cechy:\", rejected_features_labels)\n",
    "\n",
    "D = input_data.shape[1]\n",
    "print(f\"Input shape: {D}\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(sorted_features, sorted_mi, color='skyblue')\n",
    "plt.xlabel('Cecha')\n",
    "plt.ylabel('Informacja wzajemna')\n",
    "plt.title('Wartości informacji wzajemnej dla każdej cechy')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CVsTtXUnfchz"
   },
   "outputs": [],
   "source": [
    "train_ = int(len(input_data) * train_percent)\n",
    "validation_ = train_ + int(len(input_data) * validation_percent)\n",
    "\n",
    "X_train, Y_train = create_sliding_windows_with_labels(input_data[:train_], targets[:train_], T)\n",
    "X_test, Y_test = create_sliding_windows_with_labels(input_data[train_:], targets[train_:], T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "bavrU42_fch0",
    "outputId": "e5f45763-c8a5-4b3b-d7bd-7da692987b74"
   },
   "outputs": [],
   "source": [
    "def create_lstm_model(units=50, num_layers=1, dropout_rate=0.0, learning_rate=0.001, kernel_regularizer=0.0,\n",
    "                      rnn_activation='', dense_activation='', recurrent_dropout=0.0, dropout=0.0):\n",
    "    inn = Input(shape=(T, D))\n",
    "    x = inn\n",
    "    for i in range(num_layers):\n",
    "        return_sequences = True if i < num_layers - 1 else False\n",
    "        kernel_regularizer = l2(kernel_regularizer) if i == 0 else None\n",
    "        x = LSTM(units, return_sequences=return_sequences, activation=rnn_activation,\n",
    "                 kernel_regularizer=kernel_regularizer, dropout=dropout_rate, recurrent_dropout=recurrent_dropout)(x)\n",
    "    x = Dense(units, activation=dense_activation)(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=inn, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_rnn_model(units=50, num_layers=1, dropout_rate=0.0, learning_rate=0.001, kernel_regularizer=0.0,\n",
    "                     rnn_activation='', dense_activation='', recurrent_dropout=0.0, dropout=0.0):\n",
    "    inn = Input(shape=(T, D))\n",
    "    x = inn\n",
    "    for i in range(num_layers):\n",
    "        return_sequences = True if i < num_layers - 1 else False\n",
    "        kernel_regularizer = l2(kernel_regularizer) if i == 0 else None\n",
    "        x = SimpleRNN(units, return_sequences=return_sequences, activation=rnn_activation,\n",
    "                      kernel_regularizer=kernel_regularizer, dropout=dropout_rate, recurrent_dropout=recurrent_dropout)(\n",
    "            x)\n",
    "    x = Dense(units, activation=dense_activation)(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=inn, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_gru_model(units=50, num_layers=1, dropout_rate=0.0, learning_rate=0.001, kernel_regularizer=0.0,\n",
    "                     rnn_activation='', dense_activation='', recurrent_dropout=0.0, dropout=0.0):\n",
    "    inn = Input(shape=(T, D))\n",
    "    x = inn\n",
    "    for i in range(num_layers):\n",
    "        return_sequences = True if i < num_layers - 1 else False\n",
    "        kernel_regularizer = l2(kernel_regularizer) if i == 0 else None\n",
    "        x = GRU(units, return_sequences=return_sequences, activation=rnn_activation,\n",
    "                kernel_regularizer=kernel_regularizer, dropout=dropout_rate, recurrent_dropout=recurrent_dropout)(x)\n",
    "    x = Dense(units, activation=dense_activation)(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=inn, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_cnn_model(units=50, num_layers=1, learning_rate=0.001, kernel_regularizer=0.0,\n",
    "                     rnn_activation='', dense_activation='', dropout=0.0):\n",
    "    inn = Input(shape=(T, D))\n",
    "    x = inn\n",
    "    for i in range(num_layers):\n",
    "        kernel_regularizer = l2(kernel_regularizer) if i == 0 else None\n",
    "        x = Conv1D(units, kernel_size=3, activation=rnn_activation, padding='same',\n",
    "                   kernel_regularizer=kernel_regularizer)(x)\n",
    "\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units, activation=dense_activation)(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=inn, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=5)\n",
    "clf = KerasClassifier(model=create_gru_model, units=None, num_layers=None, dropout_rate=None, learning_rate=None,\n",
    "                      kernel_regularizer=None, rnn_activation=None, dense_activation=None, recurrent_dropout=None,\n",
    "                      dropout=None)\n",
    "\n",
    "param_grid = {\n",
    "    'clf__units': [64, 128, 192, 256],\n",
    "    'clf__num_layers': [1, 2],\n",
    "    'clf__dropout': [0.1, 0.2, 0.3],\n",
    "    'clf__batch_size': [32, 64, 128],\n",
    "    'clf__epochs': [16, 32, 64, 100],\n",
    "    'clf__dense_activation': ['relu', 'sigmoid', 'softmax'],\n",
    "    'clf__kernel_regularizer': [1e-3],\n",
    "    'clf__learning_rate': [0.001],\n",
    "    'clf__recurrent_dropout': [0.0],\n",
    "    'clf__dropout_rate': [0.0],\n",
    "    'clf__rnn_activation': ['tanh']\n",
    "}\n",
    "\n",
    "# clf = KerasClassifier(model=create_gru_model, units=None, num_layers=None, dropout_rate=None, learning_rate=None,\n",
    "#                       kernel_regularizer=None, rnn_activation=None, dense_activation=None, recurrent_dropout=None,\n",
    "#                       dropout=None)\n",
    "# param_grid = {\n",
    "#     'clf__units': [64, 128, 192, 256],\n",
    "#     'clf__num_layers': [1, 2],\n",
    "#     'clf__dropout': [0.1, 0.2, 0.3],\n",
    "#     'clf__batch_size': [32, 64, 128],\n",
    "#     'clf__epochs': [16, 32, 64, 100],\n",
    "#     'clf__dense_activation': ['relu', 'sigmoid', 'softmax'],\n",
    "#     'clf__kernel_regularizer': [1e-3],\n",
    "#     'clf__learning_rate': [0.001],\n",
    "#     'clf__recurrent_dropout': [0.0],\n",
    "#     'clf__dropout_rate': [0.0],\n",
    "#     'clf__rnn_activation': ['tanh']\n",
    "# }\n",
    "\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, zero_division=np.nan, average='binary'),\n",
    "    'recall': make_scorer(recall_score, zero_division=np.nan, average='binary'),\n",
    "    'f1_score': make_scorer(f1_score, zero_division=np.nan, average='binary'),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', (NDStandardScaler(feature_range=(-1, 1)))),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=param_grid, verbose=0, n_iter=1,\n",
    "                                   cv=TimeSeriesSplit(n_splits=6),\n",
    "                                   scoring=scoring, refit='accuracy', return_train_score=False,\n",
    "                                   random_state=random_seed)\n",
    "random_result = random_search.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Najlepsze parametry: %s\" % random_result.best_params_)\n",
    "print(\"Najlepsze wyniki dla accuracy: %s\" % random_result.best_score_)\n",
    "\n",
    "results = random_result.cv_results_\n",
    "best_model = random_result.best_estimator_\n",
    "Y_pred = best_model.predict(X_test)\n",
    "\n",
    "best_index = random_result.best_index_\n",
    "print(f\"Mean test accuracy: {results['mean_test_accuracy'][best_index]:.3f}\")\n",
    "print(f\"Mean test precision: {results['mean_test_precision'][best_index]:.3f}\")\n",
    "print(f\"Mean test recall: {results['mean_test_recall'][best_index]:.3f}\")\n",
    "print(f\"Mean test f1_score: {results['mean_test_f1_score'][best_index]:.3f}\")\n",
    "print(f\"Mean test roc_auc: {results['mean_test_roc_auc'][best_index]:.3f}\")\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred, average='binary', zero_division=np.nan)\n",
    "recall = recall_score(Y_test, Y_pred, average='binary', zero_division=np.nan)\n",
    "f1 = f1_score(Y_test, Y_pred, average='binary', zero_division=np.nan)\n",
    "roc_auc = roc_auc_score(Y_test, Y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "print(f\"F1 Score: {f1:.3f}\")\n",
    "print(f\"ROC/AUC: {roc_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "B6SdczwVfch1",
    "outputId": "1a1a3383-dccb-46bc-e7da-4cdf2dd75eab"
   },
   "outputs": [],
   "source": [
    "for mean, std, params in zip(results['mean_test_accuracy'], results['std_test_accuracy'], results['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) dla %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "UvlnVZ5jfch1",
    "outputId": "1b25fcd3-7a92-4f25-a2b7-ef5a00a5b126"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(Y_test, Y_pred, labels=[True, False]),\n",
    "                              display_labels=['Long', 'Short'])\n",
    "\n",
    "disp.plot()\n",
    "plt.xlabel('Przewidywane klasy')\n",
    "plt.ylabel('Prawdziwe klasy')\n",
    "plt.title('Macierz pomyłek')\n",
    "plt.show()\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "Y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, Y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('Wskaźnik fałszywie pozytywnych')\n",
    "plt.ylabel('Wskaźnik prawdziwie pozytywnych')\n",
    "plt.title('Krzywa ROC dla najlepszego modelu')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
